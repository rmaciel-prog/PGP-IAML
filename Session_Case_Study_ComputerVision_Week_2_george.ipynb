{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session_Case_Study_ComputerVision_Week_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQl-nIDDCA53",
        "colab_type": "text"
      },
      "source": [
        "# Case Study - Image Classification using Deep CNN in Keras.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFEKKMXICF9X",
        "colab_type": "text"
      },
      "source": [
        "<h1>Context<h1/>\n",
        "\n",
        "- The CIFAR-10 dataset contains 60,000 32x32 color images in 10 different classes.\n",
        "- The 10 different classes represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks.\n",
        "- There are 6,000 images of each class.\n",
        "\n",
        "<h2>Understand the labels:<h2/>\n",
        "\n",
        "- airplane : 0\n",
        "- automobile : 1\n",
        "- bird : 2\n",
        "- cat : 3\n",
        "- deer : 4\n",
        "- dog : 5\n",
        "- frog : 6\n",
        "- horse : 7\n",
        "- ship : 8\n",
        "- truck : 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Epsl8aAGNPej",
        "colab_type": "text"
      },
      "source": [
        "## George's Challenge\n",
        "What type of classification is this?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNIN3s1kHmTB",
        "colab_type": "text"
      },
      "source": [
        "<h1>Problem Statement<h1/>\n",
        "\n",
        "- Image Classification using Deep CNN in Keras and also some edge detection operation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoVbZ22GICCo",
        "colab_type": "text"
      },
      "source": [
        "<h1>Import all necessary modules and load the data<h1/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6bjW33oQvDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import necessary modules.\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e21_TQyARLdf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the batch size, number of epochs.\n",
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 30\n",
        "num_predictions = 20"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ag1mlSAiRSsR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b19cec14-a841-4c43-abdf-b19f052fd3e2"
      },
      "source": [
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pXTYLk2Idol",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6ddfe6e3-a639-4edd-a1b4-2f882503c7d9"
      },
      "source": [
        "# Print the shape of dataset.\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-wVAMfGnFij",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a969d38-dc24-4286-9e86-7bc131bdc3dd"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4EU-Du3CeCr",
        "colab_type": "text"
      },
      "source": [
        "- The training set contains 50000 images.\n",
        "- The size of each image is 32x32 pixels.\n",
        "- Each image has 3 color channels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-5Y28Hf7-tq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2951b3f0-408e-4e69-c49e-acd84aedfb11"
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnXS2u8UNgv_",
        "colab_type": "text"
      },
      "source": [
        "## George's Challenge\n",
        "- How to select the 10th image?\n",
        "- How to get the red pixels only?\n",
        "- What is the shape of resulting array?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVWDHNjrCy9P",
        "colab_type": "text"
      },
      "source": [
        "- The label of image at index = 0 is 6:\"frog\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s12yUeMB662K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_dict =  {0:'airplane', 1:'automobile', 2:'bird', 3:'cat', 4:'deer', 5:'dog', 6:'frog', 7:'horse', 8:'ship', 9:'truck'}"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKIYRyxsxCeK",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "<h2>Explore the Data<h3/>\n",
        "\n",
        "- Understanding a dataset is part of making predictions on the data. \n",
        "- It answers some of questions like in a given data..\n",
        "  - \"What are the possible labels?\"\n",
        "  - \"What is the range of pixel values for the image data?\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66qUQg6OxcsL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "d78c6ca8-d35b-4ea0-97f2-0161e18b5f95"
      },
      "source": [
        "i = 0\n",
        "image = x_train[i]\n",
        "label = y_train[i][0]\n",
        "print(' Label \\n Label Id: {} \\n Name: {}'.format(label, label_dict[label]))\n",
        "plt.imshow(image);"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Label \n",
            " Label Id: 6 \n",
            " Name: frog\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZKivFaZDB7I",
        "colab_type": "text"
      },
      "source": [
        "- The above image of a frog.\n",
        "- The Label ID is 6.\n",
        "- As we can see the x-axis and y-axis of image, it shows that there are 32 pixels on each directions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMOKU7ZxPOrJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5d389036-265d-4444-9673-d08496d35c47"
      },
      "source": [
        "image.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGR-V6nLnllx",
        "colab_type": "text"
      },
      "source": [
        "## George's Challenge\n",
        "- Without checking, what is the shape of `image`\n",
        "- How to rewrite the print statement using `f-string`?\n",
        "- Why do we need to use `[0]` in `label = y_train[i][0]`?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aq0rkOOT8nfI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "a57b158f-9e3a-441f-b950-f9d8ed7e7772"
      },
      "source": [
        "sobel = cv2.Sobel(image, cv2.CV_64F, 1, 1, ksize=5)\n",
        "plt.imshow(sobel)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fdd327e8dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0ghOfUzDRP3",
        "colab_type": "text"
      },
      "source": [
        "- As the image quality is not good, the edges are not so good. But still we can visualize that there are edges."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7kVqDH8RUNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Convert class vectors to binary class matrices.\n",
        "## One hot encore labels 0, 1, .., 9 to [0, 0, .., 1, 0, 0]\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXcwUyNdvuet",
        "colab_type": "text"
      },
      "source": [
        "## George's Challenge\n",
        "Why do we need to one-hot encode the labels?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xlCscLsouHY",
        "colab_type": "text"
      },
      "source": [
        "## George's Tip\n",
        "There are many tools to one-hot encode and they differ in syntax, but the keras one is probably best implemented.\n",
        "- `keras.utils.to_categorical`\n",
        "- `sklearn.preprocessing.OneHotEncoder`\n",
        "- `pandas get_dummies`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWSN8LRypurr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "y = [[0], [1], [2], [3]]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8LkvYcVwJL9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "689ae1ae-2ae9-4691-a2b9-ef5990d15b85"
      },
      "source": [
        "keras.utils.to_categorical(y)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nycvBjOiwN4a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "62a376a6-3304-46ee-c77f-0c1928889cf3"
      },
      "source": [
        "ohe = OneHotEncoder()\n",
        "ohe.fit_transform(y).toarray()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5k4jHGiSwR0F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "01d728a5-104b-4b76-b6a5-88da7cf50fd3"
      },
      "source": [
        "y = [0, 1, 2, 3]\n",
        "pd.get_dummies(y).values"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, 0],\n",
              "       [0, 1, 0, 0],\n",
              "       [0, 0, 1, 0],\n",
              "       [0, 0, 0, 1]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRk1hd2llEXG",
        "colab_type": "text"
      },
      "source": [
        "<h1>Create the Model:<h1/>\n",
        "\n",
        "- Convolutional input layer, 32 feature maps with a size of 3×3 and a rectifier activation function.\n",
        "- Convolutional layer, 32 feature maps with a size of 3×3 and a rectifier activation function.\n",
        "- Max Pool layer with size 2×2.\n",
        "- Dropout layer at 25%.\n",
        "---\n",
        "- Convolutional layer, 64 feature maps with a size of 3×3 and a rectifier activation function.\n",
        "- Convolutional layer, 64 feature maps with a size of 3×3 and a rectifier activation function.\n",
        "- Max Pool layer with size 2×2.\n",
        "- Dropout layer at 25%.\n",
        "---\n",
        "- Flatten layer.\n",
        "- Fully connected layer with 512 units and a rectifier activation function.\n",
        "- Dropout layer at 50%.\n",
        "- Fully connected output layer with 10 units and a softmax activation function.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4vMBaDiHRcdt",
        "colab": {}
      },
      "source": [
        "# Create the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDIcfXrV0zRH",
        "colab_type": "text"
      },
      "source": [
        "## George's Tip\n",
        "> Activations can either be used through an Activation layer, or through the activation argument supported by all forward layers.\n",
        "\n",
        "https://keras.io/api/layers/activations/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGK2OEtgFbF1",
        "colab_type": "text"
      },
      "source": [
        "<h3>Conv2D:<h3/>\n",
        "\n",
        "- Keras Conv2D is a 2D Convolution Layer, this layer creates a convolution kernel that is wind with layers input which helps produce a tensor of outputs.\n",
        "\n",
        "<h3>Activation('relu'):<h3/>\n",
        "\n",
        "- 'relu' stands for Rectified linear unit. It is the most widely used activation function. Chiefly implemented in hidden layers of Neural network.\n",
        "- ReLu is less computationally expensive than tanh and sigmoid because it involves simpler mathematical operations. At a time only a few neurons are activated making the network sparse making it efficient and easy for computation.\n",
        "\n",
        "<h3>MaxPooling2D:<h3/>\n",
        "\n",
        "- The objective of MaxPooling Layer is to down-sample an input representation.\n",
        "- This is done to in part to help over-fitting by providing an abstracted form of the representation. As well, it reduces the computational cost by reducing the number of parameters to learn.\n",
        "\n",
        "<h3>Dropout:<h3/>\n",
        "\n",
        "- Dropout is a technique used to improve over-fit on neural networks.\n",
        "- Basically during training half of neurons on a particular layer will be deactivated. This improve generalization.\n",
        "- Normally some deep learning models use Dropout on the fully connected layers, but is also possible to use dropout after the max-pooling layers, creating some kind of image noise augmentation.\n",
        "\n",
        "<h3>Dense:<h3/>\n",
        "\n",
        "- Dense layer implements the operation: output = activation(dot(input, kernel) + bias) where activation is the element-wise activation function passed as the activation argument, kernel is a weights matrix created by the layer, and bias is a bias vector created by the layer (only applicable if use_bias is True).\n",
        "\n",
        "<h3>Softmax:<h3/>\n",
        "\n",
        "- The softmax function is also a type of sigmoid function but is handy when we are trying to handle classification problems.\n",
        "- Usually used when trying to handle multiple classes. The softmax function would squeeze the outputs for each class between 0 and 1 and would also divide by the sum of the outputs.\n",
        "______________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjBlo11J3GHg",
        "colab_type": "text"
      },
      "source": [
        "## George's Challenge\n",
        "How to handle multilabel classification?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9Bltmc3mFhQ",
        "colab_type": "text"
      },
      "source": [
        "<h4>When training the network, what you want is minimize the cost by applying a algorithm of your choice. It could be SGD, AdamOptimizer, AdagradOptimizer, or something. You have to study how each algorithm works to choose what to use, but AdamOptimizer works find for most cases in general.<h4/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwbnUwjGReRR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initiate Adam optimizer\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0001)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDiEZTmyRfmx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIAu9SmeSbT_",
        "colab_type": "text"
      },
      "source": [
        "## George's Tip\n",
        "Which loss function to use? It depends :)\n",
        "\n",
        "https://stackoverflow.com/questions/42081257/why-binary-crossentropy-and-categorical-crossentropy-give-different-performances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uN0HlTjK5ZL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "32a16cbb-5a97-421b-ca07-5af4dd2aa425"
      },
      "source": [
        "# Network structure is summarized which confirms our design was implemented correctly.\n",
        "model.summary()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,250,858\n",
            "Trainable params: 1,250,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXHjbtgluIyn",
        "colab_type": "text"
      },
      "source": [
        "- The pixel values are in the range of 0 to 255 for each of the red, green and blue channels.\n",
        "\n",
        "- It is good practice to work with normalized data. Because the input values are well understood, we can easily normalize to the range 0 to 1 by dividing each value by the maximum observation which is 255.\n",
        "\n",
        "- Note, the data is loaded as integers, so we must cast it to floating point values in order to perform the division."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdy_QO9tRifH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.astype('float32') # Conversion to float type from integer type.\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255.0 # Division by 255\n",
        "x_test /= 255.0"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hbe2G_w9bvNh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c34c0b9f-1db1-48a2-a098-d756ebb07363"
      },
      "source": [
        "#Adding Early stopping callback to the fit function is going to stop the training,\n",
        "#if the val_loss is not going to change even '0.001' for more than 10 continous epochs\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=10)\n",
        "\n",
        "#Adding Model Checkpoint callback to the fit function is going to save the weights whenever val_loss achieves a new low value. \n",
        "#Hence saving the best weights occurred during training\n",
        "\n",
        "model_checkpoint =  ModelCheckpoint('cifar_cnn_checkpoint_{epoch:02d}_loss{val_loss:.4f}.h5',\n",
        "                                                           monitor='val_loss',\n",
        "                                                           verbose=1,\n",
        "                                                           save_best_only=True,\n",
        "                                                           save_weights_only=True,\n",
        "                                                           mode='auto',\n",
        "                                                           period=1)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7kTtlDB2jxX",
        "colab_type": "text"
      },
      "source": [
        "## George's Tip\n",
        "> Passing an integer after the ':' will cause that field to be a minimum number of characters wide. This is useful for making columns line up.\n",
        "\n",
        "https://docs.python.org/3/tutorial/inputoutput.html#:~:text=There%20are%20several%20ways%20to%20format%20output.,to%20variables%20or%20literal%20values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aG-R9GYunmf",
        "colab_type": "text"
      },
      "source": [
        "<h2>Fit the model:<h2/>\n",
        "\n",
        "-  We can fit this model with 30 epochs and a batch size of 32.\n",
        "\n",
        "- A small number of epochs was chosen to quickly run the code so we can understand the concepts ahead. Normally the number of epochs would be one or two orders of magnitude larger for this problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0ubfQ0kRl1G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cdfb2746-cdf2-43cd-84d7-214828bd1928"
      },
      "source": [
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=(x_test, y_test),\n",
        "          shuffle=True,\n",
        "          verbose=1,\n",
        "          callbacks=[early_stopping,model_checkpoint])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 2.1165 - accuracy: 0.2174\n",
            "Epoch 00001: val_loss improved from inf to 1.98225, saving model to cifar_cnn_checkpoint_01_loss1.9823.h5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.1165 - accuracy: 0.2174 - val_loss: 1.9823 - val_accuracy: 0.2840\n",
            "Epoch 2/30\n",
            "1557/1563 [============================>.] - ETA: 0s - loss: 1.9711 - accuracy: 0.2827\n",
            "Epoch 00002: val_loss improved from 1.98225 to 1.89885, saving model to cifar_cnn_checkpoint_02_loss1.8989.h5\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.9708 - accuracy: 0.2827 - val_loss: 1.8989 - val_accuracy: 0.3095\n",
            "Epoch 3/30\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 1.9110 - accuracy: 0.3061\n",
            "Epoch 00003: val_loss improved from 1.89885 to 1.83276, saving model to cifar_cnn_checkpoint_03_loss1.8328.h5\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.9109 - accuracy: 0.3062 - val_loss: 1.8328 - val_accuracy: 0.3495\n",
            "Epoch 4/30\n",
            "1559/1563 [============================>.] - ETA: 0s - loss: 1.8523 - accuracy: 0.3308\n",
            "Epoch 00004: val_loss improved from 1.83276 to 1.76174, saving model to cifar_cnn_checkpoint_04_loss1.7617.h5\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.8520 - accuracy: 0.3310 - val_loss: 1.7617 - val_accuracy: 0.3730\n",
            "Epoch 5/30\n",
            "1555/1563 [============================>.] - ETA: 0s - loss: 1.7858 - accuracy: 0.3543\n",
            "Epoch 00005: val_loss improved from 1.76174 to 1.68051, saving model to cifar_cnn_checkpoint_05_loss1.6805.h5\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.7853 - accuracy: 0.3545 - val_loss: 1.6805 - val_accuracy: 0.3935\n",
            "Epoch 6/30\n",
            "1558/1563 [============================>.] - ETA: 0s - loss: 1.7056 - accuracy: 0.3851\n",
            "Epoch 00006: val_loss improved from 1.68051 to 1.60906, saving model to cifar_cnn_checkpoint_06_loss1.6091.h5\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.7057 - accuracy: 0.3852 - val_loss: 1.6091 - val_accuracy: 0.4268\n",
            "Epoch 7/30\n",
            "1560/1563 [============================>.] - ETA: 0s - loss: 1.6479 - accuracy: 0.4083\n",
            "Epoch 00007: val_loss improved from 1.60906 to 1.54891, saving model to cifar_cnn_checkpoint_07_loss1.5489.h5\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.6477 - accuracy: 0.4084 - val_loss: 1.5489 - val_accuracy: 0.4426\n",
            "Epoch 8/30\n",
            "1553/1563 [============================>.] - ETA: 0s - loss: 1.5961 - accuracy: 0.4279\n",
            "Epoch 00008: val_loss improved from 1.54891 to 1.51347, saving model to cifar_cnn_checkpoint_08_loss1.5135.h5\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.5957 - accuracy: 0.4281 - val_loss: 1.5135 - val_accuracy: 0.4585\n",
            "Epoch 9/30\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 1.5607 - accuracy: 0.4415\n",
            "Epoch 00009: val_loss improved from 1.51347 to 1.47319, saving model to cifar_cnn_checkpoint_09_loss1.4732.h5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5607 - accuracy: 0.4415 - val_loss: 1.4732 - val_accuracy: 0.4753\n",
            "Epoch 10/30\n",
            "1559/1563 [============================>.] - ETA: 0s - loss: 1.5262 - accuracy: 0.4557\n",
            "Epoch 00010: val_loss improved from 1.47319 to 1.47316, saving model to cifar_cnn_checkpoint_10_loss1.4732.h5\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.5266 - accuracy: 0.4556 - val_loss: 1.4732 - val_accuracy: 0.4740\n",
            "Epoch 11/30\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 1.5003 - accuracy: 0.4653\n",
            "Epoch 00011: val_loss improved from 1.47316 to 1.43885, saving model to cifar_cnn_checkpoint_11_loss1.4389.h5\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.5003 - accuracy: 0.4653 - val_loss: 1.4389 - val_accuracy: 0.4899\n",
            "Epoch 12/30\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 1.4783 - accuracy: 0.4725\n",
            "Epoch 00012: val_loss improved from 1.43885 to 1.41051, saving model to cifar_cnn_checkpoint_12_loss1.4105.h5\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.4781 - accuracy: 0.4726 - val_loss: 1.4105 - val_accuracy: 0.4980\n",
            "Epoch 13/30\n",
            "1552/1563 [============================>.] - ETA: 0s - loss: 1.4539 - accuracy: 0.4820\n",
            "Epoch 00013: val_loss improved from 1.41051 to 1.40778, saving model to cifar_cnn_checkpoint_13_loss1.4078.h5\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.4537 - accuracy: 0.4823 - val_loss: 1.4078 - val_accuracy: 0.5069\n",
            "Epoch 14/30\n",
            "1555/1563 [============================>.] - ETA: 0s - loss: 1.4336 - accuracy: 0.4896\n",
            "Epoch 00014: val_loss improved from 1.40778 to 1.36568, saving model to cifar_cnn_checkpoint_14_loss1.3657.h5\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.4331 - accuracy: 0.4898 - val_loss: 1.3657 - val_accuracy: 0.5193\n",
            "Epoch 15/30\n",
            "1554/1563 [============================>.] - ETA: 0s - loss: 1.4143 - accuracy: 0.4977\n",
            "Epoch 00015: val_loss improved from 1.36568 to 1.34651, saving model to cifar_cnn_checkpoint_15_loss1.3465.h5\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.4140 - accuracy: 0.4978 - val_loss: 1.3465 - val_accuracy: 0.5254\n",
            "Epoch 16/30\n",
            "1552/1563 [============================>.] - ETA: 0s - loss: 1.3962 - accuracy: 0.5035\n",
            "Epoch 00016: val_loss improved from 1.34651 to 1.32798, saving model to cifar_cnn_checkpoint_16_loss1.3280.h5\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.3958 - accuracy: 0.5036 - val_loss: 1.3280 - val_accuracy: 0.5326\n",
            "Epoch 17/30\n",
            "1551/1563 [============================>.] - ETA: 0s - loss: 1.3779 - accuracy: 0.5131\n",
            "Epoch 00017: val_loss did not improve from 1.32798\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.3781 - accuracy: 0.5130 - val_loss: 1.3296 - val_accuracy: 0.5297\n",
            "Epoch 18/30\n",
            "1558/1563 [============================>.] - ETA: 0s - loss: 1.3605 - accuracy: 0.5171\n",
            "Epoch 00018: val_loss improved from 1.32798 to 1.30400, saving model to cifar_cnn_checkpoint_18_loss1.3040.h5\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.3607 - accuracy: 0.5171 - val_loss: 1.3040 - val_accuracy: 0.5388\n",
            "Epoch 19/30\n",
            "1557/1563 [============================>.] - ETA: 0s - loss: 1.3416 - accuracy: 0.5247\n",
            "Epoch 00019: val_loss improved from 1.30400 to 1.28073, saving model to cifar_cnn_checkpoint_19_loss1.2807.h5\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.3418 - accuracy: 0.5246 - val_loss: 1.2807 - val_accuracy: 0.5507\n",
            "Epoch 20/30\n",
            "1552/1563 [============================>.] - ETA: 0s - loss: 1.3262 - accuracy: 0.5279\n",
            "Epoch 00020: val_loss improved from 1.28073 to 1.27614, saving model to cifar_cnn_checkpoint_20_loss1.2761.h5\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.3258 - accuracy: 0.5280 - val_loss: 1.2761 - val_accuracy: 0.5518\n",
            "Epoch 21/30\n",
            "1556/1563 [============================>.] - ETA: 0s - loss: 1.3094 - accuracy: 0.5353\n",
            "Epoch 00021: val_loss improved from 1.27614 to 1.26575, saving model to cifar_cnn_checkpoint_21_loss1.2658.h5\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.3093 - accuracy: 0.5354 - val_loss: 1.2658 - val_accuracy: 0.5546\n",
            "Epoch 22/30\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 1.2941 - accuracy: 0.5417\n",
            "Epoch 00022: val_loss improved from 1.26575 to 1.25478, saving model to cifar_cnn_checkpoint_22_loss1.2548.h5\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.2941 - accuracy: 0.5417 - val_loss: 1.2548 - val_accuracy: 0.5588\n",
            "Epoch 23/30\n",
            "1553/1563 [============================>.] - ETA: 0s - loss: 1.2812 - accuracy: 0.5462\n",
            "Epoch 00023: val_loss improved from 1.25478 to 1.24198, saving model to cifar_cnn_checkpoint_23_loss1.2420.h5\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.2812 - accuracy: 0.5462 - val_loss: 1.2420 - val_accuracy: 0.5608\n",
            "Epoch 24/30\n",
            "1559/1563 [============================>.] - ETA: 0s - loss: 1.2647 - accuracy: 0.5534\n",
            "Epoch 00024: val_loss improved from 1.24198 to 1.22497, saving model to cifar_cnn_checkpoint_24_loss1.2250.h5\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.2646 - accuracy: 0.5534 - val_loss: 1.2250 - val_accuracy: 0.5701\n",
            "Epoch 25/30\n",
            "1560/1563 [============================>.] - ETA: 0s - loss: 1.2524 - accuracy: 0.5564\n",
            "Epoch 00025: val_loss did not improve from 1.22497\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.2522 - accuracy: 0.5565 - val_loss: 1.2414 - val_accuracy: 0.5608\n",
            "Epoch 26/30\n",
            "1557/1563 [============================>.] - ETA: 0s - loss: 1.2394 - accuracy: 0.5618\n",
            "Epoch 00026: val_loss improved from 1.22497 to 1.20425, saving model to cifar_cnn_checkpoint_26_loss1.2043.h5\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.2394 - accuracy: 0.5617 - val_loss: 1.2043 - val_accuracy: 0.5748\n",
            "Epoch 27/30\n",
            "1552/1563 [============================>.] - ETA: 0s - loss: 1.2279 - accuracy: 0.5634\n",
            "Epoch 00027: val_loss improved from 1.20425 to 1.20049, saving model to cifar_cnn_checkpoint_27_loss1.2005.h5\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.2279 - accuracy: 0.5634 - val_loss: 1.2005 - val_accuracy: 0.5772\n",
            "Epoch 28/30\n",
            "1558/1563 [============================>.] - ETA: 0s - loss: 1.2152 - accuracy: 0.5712\n",
            "Epoch 00028: val_loss improved from 1.20049 to 1.18840, saving model to cifar_cnn_checkpoint_28_loss1.1884.h5\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.2152 - accuracy: 0.5711 - val_loss: 1.1884 - val_accuracy: 0.5838\n",
            "Epoch 29/30\n",
            "1560/1563 [============================>.] - ETA: 0s - loss: 1.2032 - accuracy: 0.5731\n",
            "Epoch 00029: val_loss improved from 1.18840 to 1.17423, saving model to cifar_cnn_checkpoint_29_loss1.1742.h5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2033 - accuracy: 0.5730 - val_loss: 1.1742 - val_accuracy: 0.5848\n",
            "Epoch 30/30\n",
            "1553/1563 [============================>.] - ETA: 0s - loss: 1.1893 - accuracy: 0.5806\n",
            "Epoch 00030: val_loss improved from 1.17423 to 1.17037, saving model to cifar_cnn_checkpoint_30_loss1.1704.h5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1896 - accuracy: 0.5803 - val_loss: 1.1704 - val_accuracy: 0.5900\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdd2023dac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhauG6YUvXqb",
        "colab_type": "text"
      },
      "source": [
        "<h2>Model Score:<h2/>\n",
        "\n",
        "- Once the model is fit, we evaluate it on the test dataset and print out the classification accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLXR1tDpRrO2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "330bcd7b-4e82-4d59-8362-95cc18b50b8a"
      },
      "source": [
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 1.1704 - accuracy: 0.5900\n",
            "Test loss: 1.170371413230896\n",
            "Test accuracy: 0.5899999737739563\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW5reYl7Ls3R",
        "colab_type": "text"
      },
      "source": [
        "<h3>The above score shows that the accuracy is good, as we used number of epochs = 30.\n",
        "If we use more epochs and tune the hyper-parameters more then we can get some more accuracy score. As our focus on the case study was to learn about the use of CNNs for image classification, we needed to run the code thoroughly so we set number of epochs to less. <h3/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXRH4ZQULJxx",
        "colab_type": "text"
      },
      "source": [
        "# Summary:\n",
        "\n",
        "<h3>In this case study we discovered how to create deep CNNs in Keras for image classification.<h3/>\n",
        "\n",
        "After working through this case study we learned:\n",
        "\n",
        "- About the CIFAR-10 dataset and how to load it in Keras and plot examples from the dataset.\n",
        "- How to train and evaluate a Convolutional Neural Network on the problem.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tH0ttsNkzeY_",
        "colab_type": "text"
      },
      "source": [
        "## George's Bonus $$$\n",
        "__Model training diagnosis using learning curve__\n",
        "- Early stopping https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/\n",
        "- Benefits of using pooling layers https://stats.stackexchange.com/questions/288261/why-is-max-pooling-necessary-in-convolutional-neural-networks\n",
        "- Why padding? https://stats.stackexchange.com/questions/246512/convolutional-layers-to-pad-or-not-to-pad\n",
        "- Learning Curve  https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/\n",
        "- Cross Validate Keras models  https://machinelearningmastery.com/evaluate-performance-deep-learning-models-keras/\n",
        "- More CNN's \n",
        "  - https://www.youtube.com/watch?v=YRhxdVk_sIs   \n",
        "  - https://towardsdatascience.com/simple-introduction-to-convolutional-neural-networks-cdf8d3077bac\n",
        "- Neural Network Architectures  https://towardsdatascience.com/neural-network-architectures-156e5bad51ba "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW-zCubAEg1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# initiate Adam optimizer\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=opt,\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eT_XrLYAB6s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c4431e3b-62aa-4c48-c12f-9447dd48e92a"
      },
      "source": [
        "history = model.fit(\n",
        "    x_train, \n",
        "    y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=60,\n",
        "    validation_data=(x_test, y_test),\n",
        "    shuffle=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# plot training history\n",
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7590 - accuracy: 0.3509 - val_loss: 1.4537 - val_accuracy: 0.4676\n",
            "Epoch 2/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4314 - accuracy: 0.4825 - val_loss: 1.2706 - val_accuracy: 0.5530\n",
            "Epoch 3/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2921 - accuracy: 0.5372 - val_loss: 1.1912 - val_accuracy: 0.5729\n",
            "Epoch 4/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1986 - accuracy: 0.5768 - val_loss: 1.0818 - val_accuracy: 0.6172\n",
            "Epoch 5/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1216 - accuracy: 0.6041 - val_loss: 1.0468 - val_accuracy: 0.6264\n",
            "Epoch 6/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0579 - accuracy: 0.6258 - val_loss: 0.9801 - val_accuracy: 0.6552\n",
            "Epoch 7/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0135 - accuracy: 0.6442 - val_loss: 0.9304 - val_accuracy: 0.6743\n",
            "Epoch 8/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9678 - accuracy: 0.6588 - val_loss: 0.8997 - val_accuracy: 0.6840\n",
            "Epoch 9/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9285 - accuracy: 0.6752 - val_loss: 0.8763 - val_accuracy: 0.6915\n",
            "Epoch 10/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8933 - accuracy: 0.6859 - val_loss: 0.8375 - val_accuracy: 0.7101\n",
            "Epoch 11/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8640 - accuracy: 0.6958 - val_loss: 0.8695 - val_accuracy: 0.6988\n",
            "Epoch 12/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8274 - accuracy: 0.7105 - val_loss: 0.8070 - val_accuracy: 0.7191\n",
            "Epoch 13/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7980 - accuracy: 0.7226 - val_loss: 0.7870 - val_accuracy: 0.7254\n",
            "Epoch 14/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7767 - accuracy: 0.7295 - val_loss: 0.7745 - val_accuracy: 0.7287\n",
            "Epoch 15/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7501 - accuracy: 0.7379 - val_loss: 0.7468 - val_accuracy: 0.7433\n",
            "Epoch 16/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7265 - accuracy: 0.7453 - val_loss: 0.7590 - val_accuracy: 0.7390\n",
            "Epoch 17/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7063 - accuracy: 0.7535 - val_loss: 0.7175 - val_accuracy: 0.7502\n",
            "Epoch 18/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6776 - accuracy: 0.7604 - val_loss: 0.7201 - val_accuracy: 0.7523\n",
            "Epoch 19/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6576 - accuracy: 0.7695 - val_loss: 0.7269 - val_accuracy: 0.7508\n",
            "Epoch 20/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6362 - accuracy: 0.7740 - val_loss: 0.7042 - val_accuracy: 0.7561\n",
            "Epoch 21/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6236 - accuracy: 0.7796 - val_loss: 0.6825 - val_accuracy: 0.7641\n",
            "Epoch 22/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6051 - accuracy: 0.7870 - val_loss: 0.6763 - val_accuracy: 0.7683\n",
            "Epoch 23/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5812 - accuracy: 0.7960 - val_loss: 0.6656 - val_accuracy: 0.7716\n",
            "Epoch 24/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5691 - accuracy: 0.8001 - val_loss: 0.6659 - val_accuracy: 0.7701\n",
            "Epoch 25/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5501 - accuracy: 0.8080 - val_loss: 0.6615 - val_accuracy: 0.7741\n",
            "Epoch 26/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5381 - accuracy: 0.8100 - val_loss: 0.6577 - val_accuracy: 0.7741\n",
            "Epoch 27/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5230 - accuracy: 0.8149 - val_loss: 0.6590 - val_accuracy: 0.7749\n",
            "Epoch 28/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5078 - accuracy: 0.8217 - val_loss: 0.6433 - val_accuracy: 0.7803\n",
            "Epoch 29/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4929 - accuracy: 0.8246 - val_loss: 0.6512 - val_accuracy: 0.7800\n",
            "Epoch 30/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4819 - accuracy: 0.8303 - val_loss: 0.6484 - val_accuracy: 0.7798\n",
            "Epoch 31/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4687 - accuracy: 0.8341 - val_loss: 0.6456 - val_accuracy: 0.7817\n",
            "Epoch 32/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4560 - accuracy: 0.8374 - val_loss: 0.6519 - val_accuracy: 0.7820\n",
            "Epoch 33/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4455 - accuracy: 0.8432 - val_loss: 0.6436 - val_accuracy: 0.7847\n",
            "Epoch 34/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4349 - accuracy: 0.8455 - val_loss: 0.6343 - val_accuracy: 0.7847\n",
            "Epoch 35/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4210 - accuracy: 0.8518 - val_loss: 0.6482 - val_accuracy: 0.7854\n",
            "Epoch 36/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4074 - accuracy: 0.8547 - val_loss: 0.6337 - val_accuracy: 0.7887\n",
            "Epoch 37/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3972 - accuracy: 0.8583 - val_loss: 0.6411 - val_accuracy: 0.7878\n",
            "Epoch 38/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3911 - accuracy: 0.8609 - val_loss: 0.6375 - val_accuracy: 0.7862\n",
            "Epoch 39/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3792 - accuracy: 0.8643 - val_loss: 0.6328 - val_accuracy: 0.7901\n",
            "Epoch 40/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3739 - accuracy: 0.8677 - val_loss: 0.6398 - val_accuracy: 0.7916\n",
            "Epoch 41/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3684 - accuracy: 0.8686 - val_loss: 0.6370 - val_accuracy: 0.7916\n",
            "Epoch 42/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3534 - accuracy: 0.8736 - val_loss: 0.6451 - val_accuracy: 0.7918\n",
            "Epoch 43/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3453 - accuracy: 0.8760 - val_loss: 0.6463 - val_accuracy: 0.7899\n",
            "Epoch 44/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3396 - accuracy: 0.8783 - val_loss: 0.6372 - val_accuracy: 0.7905\n",
            "Epoch 45/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3320 - accuracy: 0.8808 - val_loss: 0.6405 - val_accuracy: 0.7936\n",
            "Epoch 46/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3240 - accuracy: 0.8847 - val_loss: 0.6383 - val_accuracy: 0.7935\n",
            "Epoch 47/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3148 - accuracy: 0.8870 - val_loss: 0.6442 - val_accuracy: 0.7966\n",
            "Epoch 48/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3139 - accuracy: 0.8874 - val_loss: 0.6496 - val_accuracy: 0.7960\n",
            "Epoch 49/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3011 - accuracy: 0.8912 - val_loss: 0.6519 - val_accuracy: 0.7919\n",
            "Epoch 50/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2972 - accuracy: 0.8932 - val_loss: 0.6676 - val_accuracy: 0.7900\n",
            "Epoch 51/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2910 - accuracy: 0.8967 - val_loss: 0.6450 - val_accuracy: 0.7943\n",
            "Epoch 52/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2810 - accuracy: 0.9002 - val_loss: 0.6687 - val_accuracy: 0.7898\n",
            "Epoch 53/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2797 - accuracy: 0.9008 - val_loss: 0.6778 - val_accuracy: 0.7894\n",
            "Epoch 54/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2791 - accuracy: 0.9006 - val_loss: 0.6692 - val_accuracy: 0.7942\n",
            "Epoch 55/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2742 - accuracy: 0.9018 - val_loss: 0.6640 - val_accuracy: 0.7950\n",
            "Epoch 56/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2622 - accuracy: 0.9059 - val_loss: 0.6678 - val_accuracy: 0.7949\n",
            "Epoch 57/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2650 - accuracy: 0.9056 - val_loss: 0.6704 - val_accuracy: 0.7951\n",
            "Epoch 58/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2576 - accuracy: 0.9059 - val_loss: 0.6648 - val_accuracy: 0.7965\n",
            "Epoch 59/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2504 - accuracy: 0.9094 - val_loss: 0.6645 - val_accuracy: 0.7954\n",
            "Epoch 60/60\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2482 - accuracy: 0.9120 - val_loss: 0.6777 - val_accuracy: 0.7947\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1YHVYrdBdv3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0b6e920b-7774-46e6-bb78-b60258ae83f2"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# initiate Adam optimizer\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=opt,\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "es = EarlyStopping(\n",
        "    monitor='val_loss', \n",
        "    mode='min', \n",
        "    verbose=1, \n",
        "    patience=10, \n",
        "    min_delta=0.001\n",
        ")\n",
        "\n",
        "ckpt = ModelCheckpoint(\n",
        "    'cifar_cnn_checkpoint_{epoch:02d}_loss{val_loss:.4f}.h5', \n",
        "    monitor='val_loss', \n",
        "    verbose=1, \n",
        "    save_best_only=True,\n",
        "    mode='min'\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    x_train, \n",
        "    y_train, \n",
        "    validation_data=(x_test, y_test), \n",
        "    epochs=100, \n",
        "    verbose=1, \n",
        "    callbacks=[es, ckpt]\n",
        ")\n",
        "\n",
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1558/1563 [============================>.] - ETA: 0s - loss: 1.8014 - accuracy: 0.3358\n",
            "Epoch 00001: val_loss improved from inf to 1.48130, saving model to cifar_cnn_checkpoint_01_loss1.4813.h5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.8008 - accuracy: 0.3360 - val_loss: 1.4813 - val_accuracy: 0.4639\n",
            "Epoch 2/100\n",
            "1558/1563 [============================>.] - ETA: 0s - loss: 1.4550 - accuracy: 0.4702\n",
            "Epoch 00002: val_loss improved from 1.48130 to 1.31681, saving model to cifar_cnn_checkpoint_02_loss1.3168.h5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4550 - accuracy: 0.4702 - val_loss: 1.3168 - val_accuracy: 0.5321\n",
            "Epoch 3/100\n",
            "1555/1563 [============================>.] - ETA: 0s - loss: 1.3233 - accuracy: 0.5255\n",
            "Epoch 00003: val_loss improved from 1.31681 to 1.18158, saving model to cifar_cnn_checkpoint_03_loss1.1816.h5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3231 - accuracy: 0.5255 - val_loss: 1.1816 - val_accuracy: 0.5887\n",
            "Epoch 4/100\n",
            "1555/1563 [============================>.] - ETA: 0s - loss: 1.2243 - accuracy: 0.5662\n",
            "Epoch 00004: val_loss improved from 1.18158 to 1.11589, saving model to cifar_cnn_checkpoint_04_loss1.1159.h5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2239 - accuracy: 0.5664 - val_loss: 1.1159 - val_accuracy: 0.6075\n",
            "Epoch 5/100\n",
            "1557/1563 [============================>.] - ETA: 0s - loss: 1.1477 - accuracy: 0.5935\n",
            "Epoch 00005: val_loss improved from 1.11589 to 1.09697, saving model to cifar_cnn_checkpoint_05_loss1.0970.h5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1475 - accuracy: 0.5936 - val_loss: 1.0970 - val_accuracy: 0.6145\n",
            "Epoch 6/100\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 1.0871 - accuracy: 0.6148\n",
            "Epoch 00006: val_loss improved from 1.09697 to 0.98678, saving model to cifar_cnn_checkpoint_06_loss0.9868.h5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0871 - accuracy: 0.6148 - val_loss: 0.9868 - val_accuracy: 0.6523\n",
            "Epoch 7/100\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 1.0291 - accuracy: 0.6372\n",
            "Epoch 00007: val_loss improved from 0.98678 to 0.93625, saving model to cifar_cnn_checkpoint_07_loss0.9362.h5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0291 - accuracy: 0.6372 - val_loss: 0.9362 - val_accuracy: 0.6737\n",
            "Epoch 8/100\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.9798 - accuracy: 0.6554\n",
            "Epoch 00008: val_loss improved from 0.93625 to 0.91216, saving model to cifar_cnn_checkpoint_08_loss0.9122.h5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9799 - accuracy: 0.6554 - val_loss: 0.9122 - val_accuracy: 0.6835\n",
            "Epoch 9/100\n",
            "1553/1563 [============================>.] - ETA: 0s - loss: 0.9398 - accuracy: 0.6695\n",
            "Epoch 00009: val_loss improved from 0.91216 to 0.88122, saving model to cifar_cnn_checkpoint_09_loss0.8812.h5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9392 - accuracy: 0.6698 - val_loss: 0.8812 - val_accuracy: 0.6968\n",
            "Epoch 10/100\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.8977 - accuracy: 0.6835\n",
            "Epoch 00010: val_loss improved from 0.88122 to 0.84070, saving model to cifar_cnn_checkpoint_10_loss0.8407.h5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8978 - accuracy: 0.6836 - val_loss: 0.8407 - val_accuracy: 0.7119\n",
            "Epoch 11/100\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.8686 - accuracy: 0.6972\n",
            "Epoch 00011: val_loss improved from 0.84070 to 0.84010, saving model to cifar_cnn_checkpoint_11_loss0.8401.h5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8685 - accuracy: 0.6973 - val_loss: 0.8401 - val_accuracy: 0.7086\n",
            "Epoch 12/100\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.8325 - accuracy: 0.7082\n",
            "Epoch 00012: val_loss improved from 0.84010 to 0.80799, saving model to cifar_cnn_checkpoint_12_loss0.8080.h5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8325 - accuracy: 0.7081 - val_loss: 0.8080 - val_accuracy: 0.7211\n",
            "Epoch 13/100\n",
            "1555/1563 [============================>.] - ETA: 0s - loss: 0.8021 - accuracy: 0.7194\n",
            "Epoch 00013: val_loss improved from 0.80799 to 0.76351, saving model to cifar_cnn_checkpoint_13_loss0.7635.h5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8024 - accuracy: 0.7193 - val_loss: 0.7635 - val_accuracy: 0.7359\n",
            "Epoch 14/100\n",
            "1557/1563 [============================>.] - ETA: 0s - loss: 0.7753 - accuracy: 0.7295\n",
            "Epoch 00014: val_loss did not improve from 0.76351\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7749 - accuracy: 0.7297 - val_loss: 0.8001 - val_accuracy: 0.7234\n",
            "Epoch 15/100\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.7487 - accuracy: 0.7407\n",
            "Epoch 00015: val_loss improved from 0.76351 to 0.73110, saving model to cifar_cnn_checkpoint_15_loss0.7311.h5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7487 - accuracy: 0.7407 - val_loss: 0.7311 - val_accuracy: 0.7492\n",
            "Epoch 16/100\n",
            "1557/1563 [============================>.] - ETA: 0s - loss: 0.7235 - accuracy: 0.7462\n",
            "Epoch 00016: val_loss improved from 0.73110 to 0.72768, saving model to cifar_cnn_checkpoint_16_loss0.7277.h5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7233 - accuracy: 0.7462 - val_loss: 0.7277 - val_accuracy: 0.7508\n",
            "Epoch 17/100\n",
            "1557/1563 [============================>.] - ETA: 0s - loss: 0.7040 - accuracy: 0.7535\n",
            "Epoch 00017: val_loss improved from 0.72768 to 0.69722, saving model to cifar_cnn_checkpoint_17_loss0.6972.h5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7039 - accuracy: 0.7536 - val_loss: 0.6972 - val_accuracy: 0.7603\n",
            "Epoch 18/100\n",
            "1552/1563 [============================>.] - ETA: 0s - loss: 0.6798 - accuracy: 0.7613\n",
            "Epoch 00018: val_loss did not improve from 0.69722\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6796 - accuracy: 0.7613 - val_loss: 0.7002 - val_accuracy: 0.7594\n",
            "Epoch 19/100\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.6586 - accuracy: 0.7693\n",
            "Epoch 00019: val_loss did not improve from 0.69722\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6587 - accuracy: 0.7693 - val_loss: 0.6991 - val_accuracy: 0.7605\n",
            "Epoch 20/100\n",
            "1554/1563 [============================>.] - ETA: 0s - loss: 0.6397 - accuracy: 0.7729\n",
            "Epoch 00020: val_loss improved from 0.69722 to 0.67484, saving model to cifar_cnn_checkpoint_20_loss0.6748.h5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6395 - accuracy: 0.7729 - val_loss: 0.6748 - val_accuracy: 0.7696\n",
            "Epoch 21/100\n",
            "1557/1563 [============================>.] - ETA: 0s - loss: 0.6180 - accuracy: 0.7837\n",
            "Epoch 00021: val_loss improved from 0.67484 to 0.67342, saving model to cifar_cnn_checkpoint_21_loss0.6734.h5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6180 - accuracy: 0.7836 - val_loss: 0.6734 - val_accuracy: 0.7666\n",
            "Epoch 22/100\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.6031 - accuracy: 0.7893\n",
            "Epoch 00022: val_loss did not improve from 0.67342\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6031 - accuracy: 0.7893 - val_loss: 0.6738 - val_accuracy: 0.7715\n",
            "Epoch 23/100\n",
            "1555/1563 [============================>.] - ETA: 0s - loss: 0.5868 - accuracy: 0.7931\n",
            "Epoch 00023: val_loss improved from 0.67342 to 0.65942, saving model to cifar_cnn_checkpoint_23_loss0.6594.h5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5865 - accuracy: 0.7932 - val_loss: 0.6594 - val_accuracy: 0.7747\n",
            "Epoch 24/100\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.5701 - accuracy: 0.7992\n",
            "Epoch 00024: val_loss did not improve from 0.65942\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5701 - accuracy: 0.7992 - val_loss: 0.6640 - val_accuracy: 0.7737\n",
            "Epoch 25/100\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.5506 - accuracy: 0.8051\n",
            "Epoch 00025: val_loss improved from 0.65942 to 0.64304, saving model to cifar_cnn_checkpoint_25_loss0.6430.h5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5507 - accuracy: 0.8052 - val_loss: 0.6430 - val_accuracy: 0.7774\n",
            "Epoch 26/100\n",
            "1555/1563 [============================>.] - ETA: 0s - loss: 0.5366 - accuracy: 0.8117\n",
            "Epoch 00026: val_loss did not improve from 0.64304\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5369 - accuracy: 0.8116 - val_loss: 0.6460 - val_accuracy: 0.7812\n",
            "Epoch 27/100\n",
            "1559/1563 [============================>.] - ETA: 0s - loss: 0.5246 - accuracy: 0.8157\n",
            "Epoch 00027: val_loss improved from 0.64304 to 0.63375, saving model to cifar_cnn_checkpoint_27_loss0.6337.h5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5246 - accuracy: 0.8157 - val_loss: 0.6337 - val_accuracy: 0.7832\n",
            "Epoch 28/100\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.5112 - accuracy: 0.8198\n",
            "Epoch 00028: val_loss did not improve from 0.63375\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5112 - accuracy: 0.8198 - val_loss: 0.6350 - val_accuracy: 0.7827\n",
            "Epoch 29/100\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.4962 - accuracy: 0.8249\n",
            "Epoch 00029: val_loss improved from 0.63375 to 0.62619, saving model to cifar_cnn_checkpoint_29_loss0.6262.h5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4962 - accuracy: 0.8249 - val_loss: 0.6262 - val_accuracy: 0.7868\n",
            "Epoch 30/100\n",
            "1556/1563 [============================>.] - ETA: 0s - loss: 0.4771 - accuracy: 0.8303\n",
            "Epoch 00030: val_loss did not improve from 0.62619\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4771 - accuracy: 0.8303 - val_loss: 0.6411 - val_accuracy: 0.7874\n",
            "Epoch 31/100\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.4702 - accuracy: 0.8332\n",
            "Epoch 00031: val_loss did not improve from 0.62619\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4702 - accuracy: 0.8332 - val_loss: 0.6268 - val_accuracy: 0.7899\n",
            "Epoch 32/100\n",
            "1552/1563 [============================>.] - ETA: 0s - loss: 0.4606 - accuracy: 0.8380\n",
            "Epoch 00032: val_loss improved from 0.62619 to 0.61977, saving model to cifar_cnn_checkpoint_32_loss0.6198.h5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4607 - accuracy: 0.8380 - val_loss: 0.6198 - val_accuracy: 0.7933\n",
            "Epoch 33/100\n",
            "1555/1563 [============================>.] - ETA: 0s - loss: 0.4486 - accuracy: 0.8418\n",
            "Epoch 00033: val_loss did not improve from 0.61977\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4488 - accuracy: 0.8415 - val_loss: 0.6371 - val_accuracy: 0.7862\n",
            "Epoch 34/100\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.4337 - accuracy: 0.8484\n",
            "Epoch 00034: val_loss improved from 0.61977 to 0.61299, saving model to cifar_cnn_checkpoint_34_loss0.6130.h5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4337 - accuracy: 0.8484 - val_loss: 0.6130 - val_accuracy: 0.7941\n",
            "Epoch 35/100\n",
            "1556/1563 [============================>.] - ETA: 0s - loss: 0.4226 - accuracy: 0.8491\n",
            "Epoch 00035: val_loss did not improve from 0.61299\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4225 - accuracy: 0.8491 - val_loss: 0.6154 - val_accuracy: 0.7913\n",
            "Epoch 36/100\n",
            "1559/1563 [============================>.] - ETA: 0s - loss: 0.4114 - accuracy: 0.8541\n",
            "Epoch 00036: val_loss did not improve from 0.61299\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4114 - accuracy: 0.8540 - val_loss: 0.6326 - val_accuracy: 0.7890\n",
            "Epoch 37/100\n",
            "1557/1563 [============================>.] - ETA: 0s - loss: 0.4010 - accuracy: 0.8563\n",
            "Epoch 00037: val_loss did not improve from 0.61299\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4007 - accuracy: 0.8564 - val_loss: 0.6166 - val_accuracy: 0.7947\n",
            "Epoch 38/100\n",
            "1552/1563 [============================>.] - ETA: 0s - loss: 0.3955 - accuracy: 0.8597\n",
            "Epoch 00038: val_loss did not improve from 0.61299\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3959 - accuracy: 0.8595 - val_loss: 0.6219 - val_accuracy: 0.7935\n",
            "Epoch 39/100\n",
            "1555/1563 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8645\n",
            "Epoch 00039: val_loss did not improve from 0.61299\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3802 - accuracy: 0.8645 - val_loss: 0.6173 - val_accuracy: 0.7962\n",
            "Epoch 40/100\n",
            "1552/1563 [============================>.] - ETA: 0s - loss: 0.3704 - accuracy: 0.8686\n",
            "Epoch 00040: val_loss did not improve from 0.61299\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3703 - accuracy: 0.8687 - val_loss: 0.6319 - val_accuracy: 0.7946\n",
            "Epoch 41/100\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3636 - accuracy: 0.8684\n",
            "Epoch 00041: val_loss did not improve from 0.61299\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3634 - accuracy: 0.8684 - val_loss: 0.6284 - val_accuracy: 0.7933\n",
            "Epoch 42/100\n",
            "1552/1563 [============================>.] - ETA: 0s - loss: 0.3593 - accuracy: 0.8702\n",
            "Epoch 00042: val_loss did not improve from 0.61299\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3597 - accuracy: 0.8702 - val_loss: 0.6323 - val_accuracy: 0.7909\n",
            "Epoch 43/100\n",
            "1552/1563 [============================>.] - ETA: 0s - loss: 0.3465 - accuracy: 0.8781\n",
            "Epoch 00043: val_loss did not improve from 0.61299\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3463 - accuracy: 0.8781 - val_loss: 0.6337 - val_accuracy: 0.7954\n",
            "Epoch 44/100\n",
            "1556/1563 [============================>.] - ETA: 0s - loss: 0.3426 - accuracy: 0.8775\n",
            "Epoch 00044: val_loss did not improve from 0.61299\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3422 - accuracy: 0.8777 - val_loss: 0.6243 - val_accuracy: 0.7977\n",
            "Epoch 00044: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDzYeTo-KcDe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0afd9f79-5261-43b8-d757-c7c60c213305"
      },
      "source": [
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.6243 - accuracy: 0.7977\n",
            "Test loss: 0.624273419380188\n",
            "Test accuracy: 0.7976999878883362\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOu_4OZtrhmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 27,
      "outputs": []
    }
  ]
}